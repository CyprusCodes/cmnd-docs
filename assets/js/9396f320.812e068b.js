"use strict";(self.webpackChunkmy_website=self.webpackChunkmy_website||[]).push([[2185],{7537:(o,e,t)=>{t.r(e),t.d(e,{assets:()=>a,contentTitle:()=>l,default:()=>u,frontMatter:()=>i,metadata:()=>r,toc:()=>c});var n=t(4848),s=t(8453);const i={id:"post-tool-call",title:"Post Tool Call",description:"How to control LLM behavior after a tool call using `postCallPrompt`.",sidebar_position:1},l="Post Tool Call",r={id:"cmnd-custom-tools/configuration_options/post-tool-call",title:"Post Tool Call",description:"How to control LLM behavior after a tool call using `postCallPrompt`.",source:"@site/docs/cmnd-custom-tools/configuration_options/post-tool-call-prompt.md",sourceDirName:"cmnd-custom-tools/configuration_options",slug:"/cmnd-custom-tools/configuration_options/post-tool-call",permalink:"/docs/cmnd-custom-tools/configuration_options/post-tool-call",draft:!1,unlisted:!1,tags:[],version:"current",sidebarPosition:1,frontMatter:{id:"post-tool-call",title:"Post Tool Call",description:"How to control LLM behavior after a tool call using `postCallPrompt`.",sidebar_position:1},sidebar:"tutorialSidebar",previous:{title:"Configuration Options",permalink:"/docs/category/configuration-options-2"},next:{title:"Rerun",permalink:"/docs/cmnd-custom-tools/configuration_options/rerun"}},a={},c=[{value:"What It Does",id:"what-it-does",level:2},{value:"Why Use It?",id:"why-use-it",level:2},{value:"Example",id:"example",level:2},{value:"Summary",id:"summary",level:2}];function d(o){const e={admonition:"admonition",code:"code",h1:"h1",h2:"h2",header:"header",hr:"hr",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,s.R)(),...o.components};return(0,n.jsxs)(n.Fragment,{children:[(0,n.jsx)(e.header,{children:(0,n.jsx)(e.h1,{id:"post-tool-call",children:"Post Tool Call"})}),"\n",(0,n.jsx)(e.p,{children:"In AI-driven workflows, the interaction between tools and the language model often requires contextual follow-up. Sometimes a tool succeeds, other times it fails \u2014 and you may want the LLM to react differently depending on the result."}),"\n",(0,n.jsxs)(e.p,{children:["To support this, CMND.ai introduces ",(0,n.jsx)(e.strong,{children:"Post-Tool Call Prompting"}),", a technique that allows you to dynamically guide the LLM\u2019s response based on the outcome of a tool execution."]}),"\n",(0,n.jsx)(e.hr,{}),"\n",(0,n.jsx)(e.h2,{id:"what-it-does",children:"What It Does"}),"\n",(0,n.jsxs)(e.p,{children:["Each tool can define a ",(0,n.jsx)(e.code,{children:"postCallPrompt"}),", which is injected into the system prompt ",(0,n.jsx)(e.strong,{children:"after the tool completes"})," but ",(0,n.jsx)(e.strong,{children:"before the LLM responds to the user"}),"."]}),"\n",(0,n.jsx)(e.p,{children:"This gives you a chance to influence the assistant\u2019s next message \u2014 based on success, failure, or specific outputs from the tool."}),"\n",(0,n.jsx)(e.hr,{}),"\n",(0,n.jsx)(e.h2,{id:"why-use-it",children:"Why Use It?"}),"\n",(0,n.jsxs)(e.ul,{children:["\n",(0,n.jsx)(e.li,{children:"Adjust the assistant\u2019s response based on real-world tool results"}),"\n",(0,n.jsx)(e.li,{children:"Handle success/failure cases with more clarity"}),"\n",(0,n.jsx)(e.li,{children:"Improve the flow of conversations without requiring custom post-processing"}),"\n"]}),"\n",(0,n.jsx)(e.hr,{}),"\n",(0,n.jsx)(e.h2,{id:"example",children:"Example"}),"\n",(0,n.jsx)(e.p,{children:"Let\u2019s say you have a tool for handling user login. You want the assistant to prompt for retry on failure, or continue normally on success."}),"\n",(0,n.jsx)(e.pre,{children:(0,n.jsx)(e.code,{className:"language-python",metastring:'title="Tool with postCallPrompt"',children:'{\n    "name": "user_login",\n    "description": "Login tool that takes a username and password, and returns an access token",\n    "parameters": custom_json_schema(UserLoginSchema),\n    "runCmd": user_login,\n    "isDangerous": False,\n    "functionType": "backend",\n    "isLongRunningTool": False,\n    "postCallPrompt": "If the login tool output is failure, ask the user to try again. If successful, continue the conversation."\n}\n'})}),"\n",(0,n.jsx)(e.p,{children:"This prompt is merged with the system prompt and provides real-time context to the LLM, without needing any manual handling on your backend."}),"\n",(0,n.jsx)(e.hr,{}),"\n",(0,n.jsx)(e.admonition,{title:"Best Practices",type:"tip",children:(0,n.jsxs)(e.ul,{children:["\n",(0,n.jsxs)(e.li,{children:["Be ",(0,n.jsx)(e.strong,{children:"clear and specific"})," in your ",(0,n.jsx)(e.code,{children:"postCallPrompt"}),". The LLM needs precise instructions to behave consistently."]}),"\n",(0,n.jsx)(e.li,{children:"Use this feature for decision points in your flow \u2014 such as login, verification, search results, or validations."}),"\n",(0,n.jsx)(e.li,{children:"Avoid duplicating logic that\u2019s already enforced in your backend \u2014 use this for communication flow only."}),"\n"]})}),"\n",(0,n.jsx)(e.hr,{}),"\n",(0,n.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,n.jsxs)(e.ul,{children:["\n",(0,n.jsxs)(e.li,{children:[(0,n.jsx)(e.code,{children:"postCallPrompt"})," lets you guide the LLM\u2019s response after a tool call."]}),"\n",(0,n.jsx)(e.li,{children:"It supports smoother user experiences by reacting intelligently to tool outcomes."}),"\n",(0,n.jsx)(e.li,{children:"Use it in any tool where the result should affect what the assistant says next."}),"\n"]}),"\n",(0,n.jsx)(e.p,{children:"This is especially powerful in assistant flows that involve real-time actions \u2014 such as authentication, transactions, or search \u2014 where context and control really matter."})]})}function u(o={}){const{wrapper:e}={...(0,s.R)(),...o.components};return e?(0,n.jsx)(e,{...o,children:(0,n.jsx)(d,{...o})}):d(o)}},8453:(o,e,t)=>{t.d(e,{R:()=>l,x:()=>r});var n=t(6540);const s={},i=n.createContext(s);function l(o){const e=n.useContext(i);return n.useMemo((function(){return"function"==typeof o?o(e):{...e,...o}}),[e,o])}function r(o){let e;return e=o.disableParentContext?"function"==typeof o.components?o.components(s):o.components||s:l(o.components),n.createElement(i.Provider,{value:e},o.children)}}}]);